---
title: "Attention Lecture 3"
title-slide-attributes:
  data-background-image: images/threeWiseMonkeys/Three_Wise_Monkeys_640px.jpeg
  data-background-size: contain
  data-background-opacity: "0.5"
author: "Alex Holcombe"
date: today
format: 
  revealjs:
    incremental: true
    self-contained: false
    slide-number: c/t
    logo: "images/threeWiseMonkeys/monkeyNoHearHeadOnly.jpeg"
    footer: "[PSYC2016: Attention](https://alexholcombe.github.io/PSYC2016lectures)"
    theme: ["simple", "styles.scss"]
    echo: true
    multiplex: false
    code-link: true
    title-slide-attributes:
      data-background-color: "#447099"
editor: source
---

<!--sometimes have to turn multiplex false to load speaker notes -->

<!--As for the format of the quizzes, we can’t sit all people in the Monday class, so I give the quiz question at the end and will explain it first thing on tuesday.  The quiz question is open until 3pm Tuesday.  For the Tuesday and Thursday class, the quiz opens at the start, but I explain it after it closes at 3:50pm. I have found setting an alarm on my phone for 3:50 (or a bit later) works well to ensure that I get to it before running out of time.-->

## Lecture 2 CLEAN-UP and REVIEW

## Didn't understand:

> Location selection; can we get a demo for it like feature selection?

<BR>
[HERE](https://www.psytoolkit.org/experiment-library/experiment_cueing.html
) is an online Posner cuing experiment.


## Didn't understand:

> Will the entire textbook be assessed?

Yes but it's short, and the exam will focus on material referred to in lecture.
<BR><BR>

> The different brain regions responsible for object and feature selection

You only need to know dorsal = parietal = where = location, ventral = temporal = what = object recognition

::: notes :::
Read it on your phone, at the bus stop, while waiting for a train.
:::


## Quiz question from Lecture 1 {visibility="hidden"}

> why didn't see second letter

Why was "I missed that" the right answer

## Salience computation

![](images/brainBottomupTopdownTheeuwesFailing.png)

-   Neurons tuned to the same feature inhibit each other
-   Added a new paragraph on this to [Chapter 5](https://psyc2016.whatanimalssee.com/btmUpTopDown.html#btmUpTopDown)

## Features

-   Feature *dimension*s include color, motion, orientation
    -   Feature *values*: red, blue for color
    -   Feature *values*: leftward, downward for motion

## 

<BR><BR>
![](images/salienceFromFIT.png){width=50%}

-   Within a feature dimension, *salience* computation is massively parallel
    -   "parallel" = simultaneously at many locations in the visual field
    -   e.g. detecting a unique color
    
## Parallel salience processing 

![](images/parallelUniqueColorAndGraph.png)
    
## Feature processing

-   *Within* a feature dimension, salience computation is massively parallel
-   *Across* dimensions, identifying features is slow.

## {.smaller}

![](images/featureIntegrationTheorySchematic.png){width=50%}

::: {.nonincremental}
-   *Within* a feature dimension, salience computation is massively parallel
-   *Across* dimensions, identifying features is slow.
:::

::: notes :::
These two points explain many characteristics of visual search
:::

## Odd *pair* of features: *serial* processing

::: notes :::
Get ready to look for the odd pair of features
:::

##

![](images/serialUniqueConjunction.png)

## Odd *pair* of features: *serial* processing

![](images/serialUniqueConjunctionAndGraph.png)

## Feature integration theory of Anne Treisman

![](images/featureIntegrationTheorySchematic.png)

## {background-image="images/hardQuiz.jpg" background-opacity="0.8"}

::: notes :::
Monday quiz. Remains open until 3pm Tues.
:::

## {background-image="images/hardQuiz.jpg" background-opacity="0.2"}

According to Treisman's feature integration theory, when search is serial, what is also true?

A. It usually involves search for a single feature (such as "blue")

B. The person has been distracted by a unique item

C. Motion is one of the features involved

D. Focused attention has to visit each location

::: notes :::
LECTURE 3 QUIZ
According to Treisman's feature integration theory, when search is serial what is also true?

A. It usually involves search for a single feature (such as "blue")
B. The person has been distracted by a unique item
C. Motion is one of the features involved
D. Focused attention has to visit each location
:::

## Bottlenecks ([Section 3.4](https://psyc2016.whatanimalssee.com/bottlenecks.html#bottleneckObjects) of mini-text)

-   For identifying two features from two different objects
-   For identifying features that belong to the same object

![](images/Duncan1980stimulusDotted.png){width=50%}

::: notes :::
Bottleneck for feature binding and for reporting features from two different objects
:::


## 


## Identifying feature combinations is slow

[Chapter 8](https://psyc2016.whatanimalssee.com/bindingTime.html)

{{< video images/colorMotionBindingSlow .gif >}}

```{=html}
<!-- ![](images/colorMotionBindingSlow
.gif) -->
```
## Identifying feature combinations is slow {.smaller}

Possibly doesn't occur unless selective attention routes the features through the bottleneck.

![](images/bottleneck.png){width="30%"}


## It feels like we see everything at once

-   "phenomenal content overflows cognitive access." - [Ned Block](https://royalsocietypublishing.org/doi/10.1098/rstb.2017.0353)
-   phenomenal consciousness
-   access consciousness 
-   ![](images/Alais.jpg){width=40%}

::: notes ::: 
Added to end of bottleneck chapter
it *doesn't* feel like we can only process one thing at a time. As I write these words, for example, I seem to be experiencing the whole visual field simultaneously. It doesn't feel like I can only experience one object at a time. Yet when we carefully test people on what they can report about multiple objects, if we don't give them time to move their attention around, the results suggest much processing is limited to only a few objects.
:::

## It feels like we see everything at once

-   Attention shifts so quickly we don't notice it
    -   The refrigerator light illusion
-   Something's missing from our theories

::: notes ::: 

Added to end of bottleneck chapter

it *doesn't* feel like we can only process one thing at a time. As I write these words, for example, I seem to be experiencing the whole visual field simultaneously. It doesn't feel like I can only experience one object at a time. Yet when we carefully test people on what they can report about multiple objects, if we don't give them time to move their attention around, the results suggest much processing is limited to only a few objects.

The discrepancy between what people think they experience and what information they can report is sometimes referred to as the puzzle of phenomenal experience. The simultaneous experience of the entire visual field is labelled "phenomenal consciousness" and the more limited ability to report information about the contents of visual experience has been labelled "access consciousness" 

Researchers can't yet fully explain the difference between phenomenal consciousness and access consciousness. However, they have discovered various visual processes that are *not* very capacity-limited, which can help account for some aspects of phenomenal consciousness. In the following chapters, we will go through some of these processes.
:::

## Something's missing { .smaller }

Wolfe et al. ([2011](https://www.sciencedirect.com/science/article/pii/S1364661310002536))

> a ‘selective’ path in which candidate objects must be individually selected for recognition and a ‘nonselective’ path in which information can be extracted from global and/or statistical information.

![](images/NonselectivePathwayWolfeEtAl2011.png){size=30%}


## Distraction diary: results

Menti.com

::: notes :::
DistractionDiaryRealResults
:::

##

![](images/surveyEndOfLecture.png)

## 

[globalShape.html](globalShape.html)


<!--There's a tension between simultaneous selection found by Goodbourn & Holcombe and that it takes time. So it seems the selection doesn't take much time, but rather a subsequent identification process, as hypothesized by Nishida -->




