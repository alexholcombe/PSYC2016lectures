---
title: "Attention Lecture 3"
title-slide-attributes:
  data-background-image: images/threeWiseMonkeys/Three_Wise_Monkeys_640px.jpeg
  data-background-size: contain
  data-background-opacity: "0.5"
author: "Alex Holcombe"
date: today
format: 
  revealjs:
    incremental: true
    auto-stretch: false
    self-contained: false
    slide-number: c/t
    logo: "images/threeWiseMonkeys/monkeyNoHearHeadOnly.jpeg"
    footer: "[PSYC2016: Attention](https://alexholcombe.github.io/PSYC2016lectures)"
    theme: ["simple", "styles.scss"]
    echo: true
    multiplex: false
    code-link: true
    title-slide-attributes:
      data-background-color: "#447099"
editor: source
---

<!--sometimes have to turn multiplex false to load speaker notes -->


## TODAY {background-image="images/threeWiseMonkeys/Three_Wise_Monkeys_640px.jpeg" background-opacity=".06"}

::: {.nonincremental}
-   Understanding the hand-wave and monster onset
-   Top-down vs. bottom-up attention (Ch. 5)
-   Parallel feature processing (Ch. 5, Ch. 7)
-   Absence of feature pairing (Ch. 7)
-   Feature integration theory (Ch. 9)
-   It feels like we see everything at once (Ch. 3.5)
-   Distraction experiment
:::

## Understanding the hand-wave and monster onset  {.smaller background-image="images/monster.png" background-opacity="0.2"}

-   My hand motion triggered a shift of attention to it. How?
    -   Visual cortex signals the location of odd motions
    -   Bottom-up attention encourages a shift of attention
    -   Your attention may leave my hand quickly, because it's not interesting
-   The monster appeared on the screen. 
    -   Visual cortex signalled the location of a sudden onset (Ch. 6)
    -   Bottom-up attention encourages a shift of attention
    -   Attention may linger, because the monster is interesting (top-down attention)
    
::: notes
First I said, let me get your attention over here

:::

## Bottom-up attention {.smaller background-image="images/monster.png" background-opacity="0.1"}

1) The monster appeared on the screen
    1) Visual cortex signalled the location of a sudden onset (Ch. 6)
    1) Bottom-up attention encourages a shift of attention
    1) *Only then* is the monster routed through the bottleneck and recognized to be a monster
    1) Attention may linger there, because monsters are interesting / arousing

-   Steps 2-3 happen faster than you can notice!

## Did attention go to the monster because it was a monster? NO! {.smaller background-image="images/monster.png" background-opacity="0.1"}

::: {.nonincremental}
-   The monster appeared on the screen
    -   Visual cortex signalled the location of a sudden onset (Ch. 6)
    -   Bottom-up attention encourages a shift of attention
    -   *Only then* is the monster routed throught the bottleneck and recognized to be a monster.
    -   Attention may linger there, because monsters are interesting / arousing
:::

::: notes
It happens faster than you can notice.
Determining that it is a monster requires extensive processing, selection for the bottleneck. But your bottleneck was busy processing something else! 
:::

## Parallel feature processing (Ch. 5 and 7)

![](images/bluePopoutFromBookParallelSearchSection.png){width=70%}

## Parallel feature processing {.smaller background-image="images/bluePopoutFromBookParallelSearchSection.png" background-opacity="0.15" background-size="contain"}

-   Visual cortex detects color difference
    -   Processes whole visual field simultaneously
    -   Oddball color signal propagates (salience)
    -   Drives bottom-up attention


## Parallel feature processing  {.smaller background-image="images/bluePopoutFromBookParallelSearchSection.png" background-opacity="0.05" background-size="contain"}

![](images/salienceFromFIT.png){width="50%" .absolute bottom=30 left=0}

<!-- -   Within a feature dimension, *salience* computation is massively parallel
    -   "parallel" = simultaneously at many locations in the visual field
    -   e.g. detecting a unique color
-->

## Features {background-image="images/bluePopoutFromBookParallelSearchSection.png" background-opacity="0.02"}

-   Feature *dimension*s include color, motion, orientation
    -   Feature *values*: red, blue for color
    -   Feature *values*: leftward, downward for motion

![](images/salienceFromFIT.png){width="50%" .absolute bottom=20 left=0}


## Parallel processing 

<BR>Odd feature values are salient


![](images/parallelUniqueColorAndGraph.png){.absolute bottom=0}

<!-- Make odd color displays fill the whole screen, otherwise my joke of "Have you found it yet?" doesn't work -->

## Feature processing

-   *Within* a feature dimension, salience computation is massively parallel
-   Identifying feature *combinations* is *slow*.

## Identifying feature combinations is slow {background-image="images/colorMotionBindingSlow.gif" background-size="contain"}

[Chapter 8](https://psyc2016.whatanimalssee.com/bindingTime.html)

## Identifying feature combinations is slow {.smaller}

<BR>
Possibly doesn't occur unless selective attention routes the features through the bottleneck.

![](images/bottleneck.png){height="50%"}

## From lecture 2, Didn't understand: {background-image="images/300px-Ventral-dorsal_streams.png" background-opacity="0.2" background-size="contain"}
<BR>

> The different brain regions responsible for object and feature selection

What you need to know:

-   dorsal = parietal = where = location processing
-   ventral = temporal = what = object recognition

## Feature integration theory of Treisman {.smaller}

![](images/featureIntegrationTheorySchematic.png){width=70%}

::: {.nonincremental}
-   *Within* a feature dimension, salience computation is massively parallel
-   Identifying feature combinations is slow.
:::

::: notes :::
These two points explain many characteristics of visual search
:::

## Odd *pair* of features: *serial* processing

<BR><BR>
Get ready to look for the odd pair of features!



::: notes :::
Get ready to look for the odd pair of features
:::

##

![](images/serialUniqueConjunction.png){.r-stretch}

## Odd feature pair: *serial* processing

![](images/serialUniqueConjunctionAndGraph.png)

## Feature integration theory of Treisman

![](images/featureIntegrationTheorySchematic.png){.r-stretch}

## {background-image="images/hardQuiz.jpg" background-opacity="0.8"}

::: notes :::
See question in
quizQuestionsDuringLecture.rtf
:::

## {background-image="images/hardQuiz.jpg" background-opacity="0.2"}

<!--2023 According to Treisman's Feature Integration Theory, when search is serial, what is also true?

A. It usually involves search for a single feature (such as "blue")

B. The person has been distracted by a unique item

C. Motion is one of the features involved

D. Focused attention has to visit each location-->

::: notes :::

:::

## Two letters > processing capacity

![](images/HolcombeGoodbourn/GoodbournHolcombeStimSchematic.png){.r-stretch}

## Two letters > processing capacity

<BR><BR>
![](images/HolcombeGoodbourn/GoodbournHolcombeSingleVersusDouble.png){width="30%"}

::: notes
Bottleneck - for letter identification
:::

## Feels like we see everything at once

-   "phenomenal content overflows cognitive access." - [Ned Block](https://royalsocietypublishing.org/doi/10.1098/rstb.2017.0353)
    -   "phenomenal" consciousness
-   Chapter 3.5

<!---   access consciousness 
-   ![](images/Alais.jpg){width=40%} -->

::: notes ::: 
Added to end of bottleneck chapter
it *doesn't* feel like we can only process one thing at a time. As I write these words, for example, I seem to be experiencing the whole visual field simultaneously. It doesn't feel like I can only experience one object at a time. Yet when we carefully test people on what they can report about multiple objects, if we don't give them time to move their attention around, the results suggest much processing is limited to only a few objects.
:::

## Feels like we see everything at once

↑ How can we reconcile this with the bottleneck?

<BR>

1)   Attention shifts so quickly we don't notice it
      -   The refrigerator light illusion.
1)   Something's missing from our theories?

::: notes ::: 

Added to end of bottleneck chapter

it *doesn't* feel like we can only process one thing at a time. As I write these words, for example, I seem to be experiencing the whole visual field simultaneously. It doesn't feel like I can only experience one object at a time. Yet when we carefully test people on what they can report about multiple objects, if we don't give them time to move their attention around, the results suggest much processing is limited to only a few objects.

The discrepancy between what people think they experience and what information they can report is sometimes referred to as the puzzle of phenomenal experience. The simultaneous experience of the entire visual field is labelled "phenomenal consciousness" and the more limited ability to report information about the contents of visual experience has been labelled "access consciousness" 

Researchers can't yet fully explain the difference between phenomenal consciousness and access consciousness. However, they have discovered various visual processes that are *not* very capacity-limited, which can help account for some aspects of phenomenal consciousness. In the following chapters, we will go through some of these processes.
:::

## <!--Something's missing-->

Wolfe et al. ([2011](https://www.sciencedirect.com/science/article/pii/S1364661310002536)):

> there is a ‘selective’ path in which candidate objects must be individually selected for recognition and a **‘nonselective’** path in which information can be extracted from global and/or statistical information.

-   ![](images/NonselectivePathwayWolfeEtAl2011.png){width="45%"}


## "What most often distracts you during a lecture?" {background-image="images/notificationDetoxPhoneOnly.png" background-opacity=0.3}

![](images/responses/WhatMostOftenDistractsYouDuringLecture2024.png){.r-stretch}

## "What most often distracts you during a lecture?" 

![](images/responses/WhatMostOftenDistractsYouDuringLecture2024.png)

-   Let's see what happens when we eliminate the top 2!

<!--Talk about classification into categories, from distraction lecture-->
 
## Distraction experiment {background-image="images/usingTheStopwatch.jpeg" background-opacity=0.3 background-size="200px"}
<BR>

-   Put your phone on airplane mode.
-   Turn off notifications on your computer.
-   Start the phone stopwatch (typically on Android phones, in Clock).
-   Press "lap" every time you can't help yourself and you check social media, think about something other than what you're reading, or otherwise get off task.

::: notes :::
You should be reading the mini-text anyway, so why not let it do double duty as a self-insight exercise.
::: 

## Let's spend X minutes silently reading Chapter 7

<BR>
Press 'lap' every time you get distracted.

::: notes
Then we'll answer some questions to enter our data, and about Chapter 7

I know not everyone is going to do the exercise but please don't interfere with other people.
Start the stopwatch "NOW"
:::


## Distraction experiment results {background-image="images/surveyEndOfLecture.png" background-opacity="0.5"}

<BR>

-   How many times did you press 'lap'?


::: notes :::
Menti: DistractionExperiment and End of lecture survey - didn't understand; main point, other comments
:::

## 

![](images/surveyEndOfLecture.png)

## 

[globalShape.html](globalShape.html)

::: notes :::
After going through all this and the shape slides, I still had a minute left.
:::

<!--There's a tension between simultaneous selection found by Goodbourn & Holcombe and that it takes time. So it seems the selection doesn't take much time, but rather a subsequent identification process, as hypothesized by Nishida -->




