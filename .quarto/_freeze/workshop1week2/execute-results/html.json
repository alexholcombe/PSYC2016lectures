{
  "hash": "1cf128e46b83a61ba88dd3b13eba902e",
  "result": {
    "markdown": "---\ntitle: \"PSYC3888 Can we trust this science?\"\ntitle-slide-attributes:\n    data-background-image: \"images/2targets3objectsPerArray.gif\"\n    data-background-size: contain\n    data-background-opacity: \".1\"\nformat:\n  revealjs:\n    theme: [default, mystyle.scss]\n    incremental: true\n    center: false\n    controls: true  \n---\n\n\n## Can we trust this science? {background-color=\"black\"}\n\n#### Alex Holcombe\n\n#### University of Sydney\n\n<!-- For github deployment, followed these instructions for github pages https://quarto.org/docs/publishing/github-pages.html -->\n\n\n```{=html}\n<!-- When I wrote this book one of the things I noticed was that to explain MOT and its role in the mind one mainly ended up explaining things about the mind that we know from other paradigms.\n\nNot every field of psychology is like that.\nThis is not a unified theory of tracking. That would be a different talk. This is broad empirical generalizations, the ingredients to a unified theory.\n-->\n```\n\n## Get deeper into research\n\n-   Understanding it\n-   Knowing how to use it\n-   Knowing how to do it\n\n## Research findings shouldn't be engaged with uncritically\n\n-   Knowing how to use research findings\n-   Knowing how to do research\n\n## Getting to know each other\n\nMenti.com , code: 7253 9464\n\nhttps://www.menti.com/al64txdyvg9r\n\n## The replication crisis\n\n-   Replication projects show re-running a study [often yields a different result](https://alexholcombe.wordpress.com/2023/08/08/an-executive-summary-of-sciences-replication-crisis/(opens in a new tab))\n-   One cause is [p-hacking](https://shinyapps.org/apps/p-hacker/)\n\n![](images/alexReacts.jpeg)\n\n## Assessing a scientific literature without re-doing the studies\n\n- Very hard\n- One proxy for whether a literature gets vetted is whether it's transparent ([Vazire & Holcombe, 2022](https://doi.org/10.1177/10892680211033912)\n\n![](images/JulienColomb_Open-Science.png)\n\n## Exposing the level of transparency can drive change\n\n![](images/JulienColomb_Open-Science.png)\nXYZ\n\n## Follows best practices? Has obvious errors?\n\n- Guidelines\n  - Clinical trials has heaps\n  - Other areas, not as much\n- Sample size planning\n- Statcheck\n\n<!-- https://ceramics.org/ceramic-tech-today/acers-news/open-science-open-access-projekt-deal-and-ijces/ -->\n\n## Justine's honours project\n\n::: nonincremental\n- Motivation\n- Topic\n- Process\n- Google Sheet\n:::\n\n## Groups\n\n::: nonincremental\n-   Exchange contact details.\n-   Set up a virtual workspace to exchange messages and documents, like Slack or a Facebook group\n-   Set up meetings\n:::\n\n::: notes\nIn writing this little book, I distilled the results of hundreds of studies to a short list of empirical generalizations. Broad lessons for how cognition and perception connect, it turns out.\n\nIn some ways, visual attention and memory are a coherent scientific field. I mean that findings from paradigms other than MOT generalize to MOT too.\n:::\n\n## Homework\n\n-   Do the readings\n-   Choose a research article that interests you\n    - For that article, try to fill out Justine's columns\n      - Create a copy of Google Sheet\n    - Write down notes and problems that you have\n\n::: notes\nExciting\n:::\n\n## Project process\n\n::: nonincremental\n- Identify a research area of interest\n- Identify/choose some proxies of research trustworthiness.\n- Write a plan to measure those proxies.\n- Pre-register the plan\n- Divide up the plan and do it.\n- \n:::\n\n\n## Report elements\n\n-   Evaluation of X columns?\n\n## \n\n::: notes\nA lot of people are studying the top or the bottom. Almost nobody's studying the middle We didn't have a way to get at it before.\n:::\n\n<!--Potentially add an object creation process-->\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"grViz html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-77dd974b320795442d9d\" style=\"width:960px;height:480px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-77dd974b320795442d9d\">{\"x\":{\"diagram\":\"digraph {\\n\\ngraph [layout = dot, rankdir = BT]\\n\\n# define the global styles of the nodes. We can override these in box if we wish\\nnode [shape = rectangle, style = filled, fillcolor = Linen]\\n\\n#Define the nodes\\nL [label = \\\"LH retinotopy\\\", width=5, height=1, fillcolor = firebrick]\\nR [label = \\\"RH retinotopy\\\", width=5, height=1, fillcolor = firebrick]\\nselectnLH [label =  \\\"parietal selection\\\"]\\nselectnRH [label =  \\\"parietal selection\\\"]\\noutput [label = \\\"Visual Working Memory\\\", width=6, height=2, color=White, fillcolor=gold1]\\n\\n\\n# edge definitions with the node IDs\\nedge [label=\\\"  bottleneck\\\", penwidth=.3]\\nL  -> selectnLH;\\nedge [label=\\\"\\\", penwidth=3]\\nselectnLH -> output\\n\\nedge [label=\\\"  bottleneck\\\", penwidth=.3]\\nR -> selectnRH\\nedge [label=\\\"\\\", penwidth=3]\\nselectnRH -> output\\n\\n\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n## 4.    Unitary cognition contaminates many studies\n\n![](images/attendToPartsOfSoccerPlayers.png)\n\n## 4.    Unitary cognition contaminates many studies\n\n![](images/trackingCognitiveSpotlight.png) - Always test for hemifield independence! If the effect of the factor is twice as big when you distribute targets across hemifields, it's not cognitive contamination.\n\n::: notes\nWith tracking you can actually isolate a hemisphere-specific process.\n\nI read a lot of papers that say that this factor or that factor influence MOT performance, and they imply that they've revealed something about how the tracking process works, but actually it could just be cognition following a single target and boosting performance.\n\nA role for\n:::\n\n## 5.    Crowding constrains selection: Spatial\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"grViz html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-84b3ac431c7bc78243d5\" style=\"width:960px;height:480px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-84b3ac431c7bc78243d5\">{\"x\":{\"diagram\":\"digraph {\\ngraph [layout = dot, rankdir = LR]\\n\\n# define the global styles of the nodes. We can override these in box if we wish\\nnode [shape = rectangle, style = filled, color=White, fillcolor = White, fontsize = 40]\\nnodesep=0.02;\\n\\na [label = \\\"O\\\"]\\nfixation [label =  \\\"\\\", shape=circle, fillcolor=Black, width=.2, height=.2]\\nb [label = \\\" \\\"]\\nc [label = \\\" \\\"]\\nd [label = \\\"J\\\"]\\ne [label = \\\" \\\"]\\ne2 [label = \\\" \\\"]\\ne3 [label = \\\"S\\\"]\\n\\n#add some blanks to help space the actual letters together\\nffff [label=\\\"\\\"]\\nfff [label=\\\"\\\"]\\nff [label=\\\"\\\"]\\nf [label = \\\"\\\"]\\ng [label = \\\"R\\\"]\\nh [label = \\\"L\\\"]\\ni [label = \\\"H\\\"]\\nj [label = \\\"Y\\\"]\\nk [label = \\\"M\\\"]\\nl [label = \\\"\\\"]\\nll [label=\\\"\\\"]\\nlll [label=\\\"\\\"]\\nllll [label=\\\"\\\"]\\n\\n# edge definitions with the node IDs\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\na  -> b;\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nb -> c\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nc -> d\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nd -> e\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\ne -> e2\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\ne2 -> e3\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\ne3 -> fixation\\n\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nfixation -> ffff\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nffff -> fff\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nfff -> ff\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nff -> f\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nf -> g\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\ng -> h\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nh -> i\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\ni -> j\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nj -> k\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nk -> l\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nl -> ll\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nll -> lll\\nedge [label=\\\"\\\", penwidth=0, arrowsize=0]\\nlll -> llll\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\nSpatial\n\n-   Not worse with more targets (Holcombe, Chen, & Howe, 2014)\n\n\n## WikiJournal of Science\n\n![](images/WikiJSci.jpeg)\n\nOpen access • Publication charge free • Public peer review • Wikipedia-integrated\n\n<!--https://en.wikiversity.org/wiki/WikiJournal_Preprints/Multiple_object_tracking-->\n\n::: notes\nI'm an associate editor there\n:::\n\n## WikiJournal Preprints {background-color=\"black\" background-image=\"images/2targets9objectsPerArray.gif\"}\n\n![](images/wikipreprint.png)\n\nhttps://en.wikiversity.org/wiki/WikiJournal_Preprints/Multiple_object_tracking\n\n## END {background-color=\"black\" background-image=\"images/2targets3objectsPerArray.gif\"}\n\n#### Alex Holcombe\n\n#### University of Sydney\n\n## The relationship of multiple object tracking to other forms of attention\n\n-   Feature attention is global\n-   Tracking is hemifield-specific\n\nRemaining questions:\n\n-   Is temporal resolution hemifield-specific?\n-   What about statistical perception?\n-   If you limit time of attention availability with my circular displays, does this prevent doing other tasks (dual tasks)?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/htmlwidgets-1.6.1/htmlwidgets.js\"></script>\n<script src=\"site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/grViz-binding-1.0.9/grViz.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}